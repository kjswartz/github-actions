name: Duplicate Issue Search

on:
  issues:
    types:
      - opened

permissions:
  issues: write
  models: read
  contents: read

jobs:
  prepare-batches:
    runs-on: ubuntu-latest
    outputs:
      batch_matrix: ${{ steps.batch-script.outputs.batch_matrix }}
      total_batches: ${{ steps.batch-script.outputs.total_batches }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Fetch and process issues in batches
        id: batch-script
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NEW_ISSUE_TITLE: ${{ github.event.issue.title }}
          NEW_ISSUE_BODY: ${{ github.event.issue.body }}
          NEW_ISSUE_NUMBER: ${{ github.event.issue.number }}
          REPO: ${{ github.repository }}
          BATCH_SIZE: 50
        run: |
          set -euo pipefail
          
          echo "Starting batch processing for issue duplication detection..."
          echo "New Issue #$NEW_ISSUE_NUMBER: $NEW_ISSUE_TITLE"
          echo "Will process up to approximately $NEW_ISSUE_NUMBER issues in batches of $BATCH_SIZE"
          
          # Initialize variables
          processed_count=0
          page=1
          batch_files=()
          
          time_ago=$(date -d '1 year ago' '+%Y-%m-%dT%H:%M:%SZ')
          echo "Filtering issues created after: $time_ago"

          gh api -X GET repos/$REPO/issues -f state="all" --paginate | jq --arg newNum "$NEW_ISSUE_NUMBER" --arg dateFilter "$time_ago" '.[] | select(.number != ($newNum | tonumber)) | select(.created_at >= $dateFilter) | {
            "number": .number,
            "title": .title,
            "state": .state,
            "body": .body,
            "created_at": .created_at
          }' | jq -s . > issues.txt
          
          total_issues=$(jq 'length' issues.json)
          
          # Create batch processing loop
          while [ "$processed_count" -lt "$total_issues" ]; do
            echo "Processing batch $page..."
            
            offset=$processed_count
            
            echo "Fetching issues starting from offset $offset..."
            issues_json=$(jq ".[$offset:$(($offset + $BATCH_SIZE))]" issues.json)
            
            batch_count=$(echo "$issues_json" | jq 'length')
            
            if [ "$batch_count" -eq 0 ]; then
              echo "No more issues to process. Breaking loop."
              break
            fi
            
            echo "Retrieved $batch_count issues in batch $page"
            processed_count=$((processed_count + batch_count))
            
            batch_prompt_file="batch_prompt_${page}.md"
            batch_files+=("batch_prompt_${page}")
            
            cat > "$batch_prompt_file" << EOF
          Instructions:
          You are an expert in software engineering and issue management. Compare the following new issue with the batch of existing issues and identify any duplicates or similar issues. If any of the existing issues are similar to the new issue, rate the similarity as 'HIGH', 'MEDIUM', or 'LOW'. Only include issues that have some similarity.
          Provide your response in this format for each similar issue:\n\n**Issue:** #[number] - [similarity rating]\n**Title:** [title]\n**State:** [state]\n**Reason for similarity:** [brief explanation]\n\n---\n
          If no similar issues are found in this batch, respond with an empty string or newline character.
          
          New Issue:
          Title: $NEW_ISSUE_TITLE
          Body: $NEW_ISSUE_BODY
          
          Existing Issues in this batch:
          EOF
            
            # Add each issue to the prompt
            echo "$issues_json" | jq -r '.[] | "Issue #\(.number)\nTitle: \(.title)\nBody: \(.body)\nState: \(.state)\n---"' >> "$batch_prompt_file"
          
            echo "Created prompt file: $batch_prompt_file"
            echo "Batch $page contains $batch_count issues"
          
            page=$((page + 1))
          done
          
          total_batches=$((page - 1))
          
          # Output batch information for GitHub Actions matrix
          if [ "${#batch_files[@]}" -gt 0 ]; then
            # Create properly formatted JSON array for the matrix
            batch_matrix_json="["
            for i in "${!batch_files[@]}"; do
              if [ "$i" -gt 0 ]; then
                batch_matrix_json+=","
              fi
              batch_matrix_json+="\"${batch_files[$i]}\""
            done
            batch_matrix_json+="]"
            
            echo "batch_matrix=$batch_matrix_json" >> $GITHUB_OUTPUT
            echo "total_batches=$total_batches" >> $GITHUB_OUTPUT
            
            echo "Generated matrix with ${#batch_files[@]} batches: $batch_matrix_json"
          else
            echo "batch_matrix=[]" >> $GITHUB_OUTPUT
            echo "total_batches=0" >> $GITHUB_OUTPUT
            echo "No batches created - no issues to process"
          fi
          
          # Create processing summary for output
          processing_summary="Batch Processing Summary:
          - Total batches processed: $total_batches
          - Total issues analyzed: $processed_count
          - Batch size: $BATCH_SIZE
          - New issue number: $NEW_ISSUE_NUMBER
          
          Each batch has been saved as batch_prompt_[number].md for AI analysis."
          
          echo "Batch processing completed. Processed $processed_count total issues across $total_batches batches."
          echo "$processing_summary" >> $GITHUB_STEP_SUMMARY

      - name: Upload batch files as artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: batch-files
          path: batch_prompt_*.md
          retention-days: 1

  batch-processing:
    needs: prepare-batches
    runs-on: ubuntu-latest
    if: needs.prepare-batches.outputs.total_batches > 0
    strategy:
      fail-fast: false
      matrix:
        batch_file: ${{ fromJson(needs.prepare-batches.outputs.batch_matrix) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Download batch files
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          name: batch-files

      - name: AI Inference for Batch Results
        id: ai-inference
        uses: actions/ai-inference@9693b137b6566bb66055a713613bf4f0493701eb # v1.2.3
        with:
          prompt-file: './${{ matrix.batch_file }}.md'
          token: ${{ secrets.GITHUB_TOKEN }}
          max-tokens: 2000
          model: openai/gpt-4.1

      - name: Save batch results
        env:
          AI_RESPONSE: ${{ steps.ai-inference.outputs.response }}
          BATCH_FILE: ${{ matrix.batch_file }}
        run: |
          echo "Processing AI inference results for $BATCH_FILE..."
          mkdir -p batch_results
          
          echo "Raw AI Response:"
          echo "$AI_RESPONSE"
          echo "---"

          echo "$AI_RESPONSE" > "batch_results/result_${BATCH_FILE}.md"
          echo "Successfully saved valid JSON for $BATCH_FILE"

      - name: Upload batch results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: batch-results-${{ matrix.batch_file }}
          path: batch_results/result_${{ matrix.batch_file }}.md
          retention-days: 1

  combine-results:
    needs: [prepare-batches, batch-processing]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Download all batch results
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          pattern: batch-results-*
          merge-multiple: true

      - name: Combine all results
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NEW_ISSUE_NUMBER: ${{ github.event.issue.number }}
          REPO: ${{ github.repository }}
          TOTAL_BATCHES: ${{ needs.prepare-batches.outputs.total_batches }}
        run: |
          echo "Combining results from $TOTAL_BATCHES batches..."
          
          # Create final markdown response
          echo "## Duplicate Issue Analysis Results" > final_response.md
          echo "" >> final_response.md
          
          # Check if any result files exist
          if ls result_batch_prompt_*.md 1> /dev/null 2>&1; then
            echo "Found result files, processing..."
            for result_file in result_batch_prompt_*.md; do
              if [ -f "$result_file" ]; then
                echo "Processing $result_file..."                

                cat "$result_file" >> final_response.md
                echo "" >> final_response.md
              fi
            done
            
            if ! grep -q "\*\*Issue:\*\* #\d" final_response.md; then
              echo "No duplicate issues found, posting empty response."
              echo "No duplicate or similar issues found in the analyzed batches." >> final_response.md
            fi
          else
            echo "No result files found"
            echo "No duplicate or similar issues found in the analyzed batches." >> final_response.md
          fi

      - name: Post Results
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NEW_ISSUE_NUMBER: ${{ github.event.issue.number }}
          REPO: ${{ github.repository }}
        run: |
          echo "Posting results to issue..."
          
          if [ -f "final_response.md" ]; then
            cat final_response.md >> $GITHUB_STEP_SUMMARY
            gh issue comment $NEW_ISSUE_NUMBER --repo $REPO --body-file final_response.md
            echo "Results posted successfully!"
          fi
          
          echo "Duplicate analysis workflow completed!"
